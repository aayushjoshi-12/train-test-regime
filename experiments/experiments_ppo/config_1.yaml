experiment_name: "llama3.2-qlora-ppo-w-llama3.2-rm"
model_name: "meta-llama/Meta-Llama-3-8B"
output_dir: "./models/llama3.2-qlora-ppo-w-llama3.2-rm"
data_dir: "./data"

policy_model_path: ./models/qwen2.5-3b-qlora-mortgage"
reward_model_path: "./models/reward_models/llama3.2-rm"

train_size: 1000

bnb:
  load_in_4bit: true

training:
  num_epochs: 2
  gradient_accumulation_steps: 8
  learning_rate: 1.41e-5
  weight_decay: 0.01
  lr_scheduler_type: "cosine"

lora:
  r: 16
  alpha: 32
  target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]
