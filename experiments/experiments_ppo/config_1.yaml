experiment_name: "llama3.2-qlora-ppo-w-llama3.2-rm"
model_name: "meta-llama/Meta-Llama-3-8B"
output_dir: "./models/llama3.2-qlora-ppo-w-llama3.2-rm"
data_dir: "./data"

policy_model_path: "./models/llama3.2-1b-qlora-mortgage"
reward_model_path: "./models/reward_models/llama3.2-rm"

train_size: 1000

training:
  num_epochs: 2
  gradient_accumulation_steps: 8
  learning_rate: 1.41e-5
  weight_decay: 0.01
  lr_scheduler_type: "cosine"
