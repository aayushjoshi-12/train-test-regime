experiment_name: "llama3-qlora-mortgage-k3"
model_name: "meta-llama/Meta-Llama-3-8B"
output_dir: "./models/experiment_top_k/llama3-qlora-mortgage-k5"
data_dir: "./data"

train_size: 1000
val_size: 100
test_size: 100

bnb:
  load_in_4bit: true

training:
  batch_size: 2
  num_epochs: 4
  gradient_accumulation_steps: 8
  optim: "paged_adamw_32bit"
  warmup_ratio: 0.03
  learning_rate: 2e-5
  weight_decay: 0.001
  max_grad_norm: 0.3
  lr_scheduler_type: "cosine"
  save_steps: 600
  eval_steps: 200
  save_strategy: "steps"
  load_best_model_at_end: True
  evaluation_strategy: "steps"
  group_by_length: True

lora:
  r: 16
  alpha: 32
  target_modules: ["q_proj", "v_proj", "o_proj", "k_proj"]
  modules_to_save: ["lm_head", "embed_tokens"]

test:
  temperature: 0.1
  top_k: 3 # either top_k or top_p
  # top_p: 0.95 # either top_k or top_p
